---
---

@string{aps = {American Physical Society,}}


@article{maruf24vlm4bio,
  abbr={NeurIPS 24},
  title={VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images},
  author={Maruf, M. and Daw, A. and Mehrab, K. S. and Manogaran, H.B. and Neog, A. and Sawhney, M. and Khurana, Mridul and Balhoff, James P. and Bakis, Yasin and Altintas, Bahadir and Thompson, Matthew J. and Campolongo, Elizabeth G. and Uyeda, Josef C. and Lapp, Hilmar and Bart, Henry L. and Mabee, Paula M. and Su, Yu and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Dahdul, Wasila and Karpatne, Anuj},
  abstract={Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models (VLMs). We ask if pre-trained VLMs can aid scientists in answering a range of biologically relevant questions without any additional fine-tuning. In this paper, we evaluate the effectiveness of 12 state-of-the-art (SOTA) VLMs in the field of organismal biology using a novel dataset, VLM4Bio, consisting of 469K question-answer pairs involving 30K images from three groups of organisms: fishes, birds, and butterflies, covering five biologically relevant tasks. We also explore the effects of applying prompting techniques and tests for reasoning hallucination on the performance of VLMs, shedding new light on the capabilities of current SOTA VLMs in answering biologically relevant questions using images.},
  journal = {In Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024},
  arxiv={2408.16176},
  code={https://github.com/sammarfy/VLM4Bio},
  selected={true},
  preview={vlm4bio.jpg}
}


@article{harish24hcompnet,
  abbr={NeurIPS 24},
  title={What Do You See in Common? Learning Hierarchical Prototypes over Tree-of-Life to Discover Evolutionary Traits },
  author={Manogaran, H. B. and Maruf, M. and Daw, A. and Mehrab, K. S. and Charpentier, Caleb P. and Uyeda, Josef C. and  Dahdul, Wasila and Matthew J. and Campolongo, Elizabeth G.  and Provost, Kaiya L. and Mabee, Paula M. and Lapp, Hilmar and Karpatne, Anuj},
  abstract={A grand challenge in biology is to discover evolutionary traits—features of organisms common to a group of species with a shared ancestor in the tree of life (also referred to as phylogenetic tree). With the growing availability of image repositories in biology, there is a tremendous opportunity to discover evolutionary traits directly from images in the form of a hierarchy of prototypes. However, current prototype-based methods are mostly designed to operate over a flat structure of classes and face several challenges in discovering hierarchical prototypes, including the issue of learning over-specific features at internal nodes. To overcome these challenges, we introduce the framework of Hierarchy aligned Commonality through Prototypical Networks (HComP-Net). We empirically show that HComP-Net learns prototypes that are accurate, semantically consistent, and generalizable to unseen species in comparison to baselines on birds, butterflies, and fish datasets.},
  journal = {In Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024},
  arxiv={2405.13063},
  code={https://github.com/sammarfy/VLM4Bio},
  selected={true},
  preview={hcompnet.jpg}
}

@inproceedings{khurana_hierarchical,
  abbr={ECCV 24},
  author = {Khurana, Mridul and Daw, Arka and Maruf, M. and Uyeda, Josef C. and Dahdul, Wasila and Charpentier, Caleb and Bakis, Yasin and Bart, Henry L. and Mabee, Paula M. and Lapp, Hilmar and Balhoff, James P. and Chao, Wei-Lun and Stewart, Charles and Berger-Wolf, Tanya and Karpatne, Anuj},
  title = {Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution},
  year = {2024},
  publisher = {ECCV},
  abstract = {A central problem in evolutionary biology is to explore the genetic basis of evolutionary changes in the traits of organisms, such as fin structures in fish or beak colors in birds. With the growing availability of large-scale image repositories in biology and recent advances in generative modeling, there is an opportunity to study changes in evolutionary traits of species automatically from images. We introduce a novel Hierarchical Embedding (HIER-Embed) strategy to encode the evolutionary information of a species as a composition of encodings learned at every internal node in the phylogenetic tree. We use HIER-Embeddings to condition latent diffusion models to generate synthetic images of species. Further, we introduce two novel types of perturbation operations: trait masking and trait swapping, similar in spirit to gene knockout experiments, that enable us to analyze novel changes in evolutionary traits acquired at different levels of phylogeny.},
  booktitle = {Proceedings of ECCV},
  keywords = {Evolution, Diffusion Models, Hierarchical Conditioning, Generative AI, Computer Vision},
  location = {Milan, Italy},
  preview = {phyloDiffusion.jpg},
  selected={true},
  website = {https://imageomics.github.io/phylo-diffusion},
  arxiv = {2408.00160v1},
}

@inproceedings{fishvista,
  abbr={Vision},
  author = {Mehrab*, K. S. and Maruf*, M. and Daw*, A. and Manogaran, H.B. and Neog, A. and Khurana, Mridul and Altintas, Bahadir and Bakis, Yasin and Campolongo, Elizabeth G. and Thompson, Matthew J. and Wang, Xiaojun and Lapp, Hilmar and Chao, Wei-Lun and Mabee, Paula M. and Bart, Henry L. and Dahdul, Wasila and Karpatne, Anuj},
  title = {FishVista: A Multi-Purpose Dataset for Understanding and Identification of Visual Traits from Images},
  year = {2024},
  publisher = {NeurIPS},
  booktitle = {review at NeurIPS},
  keywords = {Fine-grained Classification, Computer Vision, Imageomics, Generative AI, Dataset, AI-ready, Scientific Tasks, Organismal Biology},
  preview = {fishvista.jpg},
  code={https://github.com/sammarfy/VLM4Bio},
  arxiv={2407.08027}
}

@inproceedings{maruf2023beyond,
  abbr={Vision},
  title={Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation},
  author={Maruf, M. and Daw, Arka and Dutta, Amartya and Bu, Jie and Karpatne, Anuj},
  abstract={A central goal in deep learning is to learn compact representations of features at every layer of a neural network, which is useful for both unsupervised representation learning and structured network pruning. While there is a growing body of work in structured pruning, current state-of-the-art methods suffer from two key limitations: (i) instability during training, and (ii) need for an additional step of fine-tuning, which is resource-intensive. At the core of these limitations is the lack of a systematic approach that jointly prunes and refines weights during training in a single stage, and does not require any fine-tuning upon convergence to achieve state-of-the-art performance. We present a novel single-stage structured pruning method termed DiscriminAtive Masking (DAM). The key intuition behind DAM is to discriminatively prefer some of the neurons to be refined during the training process, while gradually masking out other neurons. We show that our proposed DAM approach has remarkably good performance over various applications, including dimensionality reduction, recommendation system, graph representation learning, and structured pruning for image classification. We also theoretically show that the learning objective of DAM is directly related to minimizing the L0 norm of the masking layer.},
  code={https://github.com/sammarfy/WS3_lib},
  booktitle={arXiv},
  preview = {ws3.jpg},
  arxiv={2308.11052},
  selected={true},
  year={2023}
}

@inproceedings{bu2021learning,
  abbr={NeurIPS 21},
  title={Learning Compact Representations of Neural Networks using DiscriminAtive Masking (DAM)},
  author={Bu*, Jie and Daw*, Arka and Maruf*, M. and Karpatne, Anuj},
  abstract={A central goal in deep learning is to learn compact representations of features at every layer of a neural network, which is useful for both unsupervised representation learning and structured network pruning. While there is a growing body of work in structured pruning, current state-of-the-art methods suffer from two key limitations: (i) instability during training, and (ii) need for an additional step of fine-tuning, which is resource-intensive. At the core of these limitations is the lack of a systematic approach that jointly prunes and refines weights during training in a single stage, and does not require any fine-tuning upon convergence to achieve state-of-the-art performance. We present a novel single-stage structured pruning method termed DiscriminAtive Masking (DAM). The key intuition behind DAM is to discriminatively prefer some of the neurons to be refined during the training process, while gradually masking out other neurons. We show that our proposed DAM approach has remarkably good performance over various applications, including dimensionality reduction, recommendation system, graph representation learning, and structured pruning for image classification. We also theoretically show that the learning objective of DAM is directly related to minimizing the L0 norm of the masking layer.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  code={https://github.com/jayroxis/dam-pytorch},
  volume={34},
  pages={3491--3503},
  selected={true},
  arxiv={2110.00684},
  preview = {dam.jpg},
  year={2021}
}


@inproceedings{daw2021pid,
  abbr={KDD 21},
  title={PID-GAN: A GAN Framework based on a Physics-informed Discriminator for Uncertainty Quantification with Physics},
  author={Daw*, Arka and Maruf*, M. and Karpatne, Anuj},
  abstract={As applications of deep learning (DL) continue to seep into critical scientific use-cases, the importance of performing uncertainty quantification (UQ) with DL has become more pressing than ever before. In scientific applications, it is also important to inform the learning of DL models with knowledge of physics of the problem to produce physically consistent and generalized solutions. This is referred to as the emerging field of physics-informed deep learning (PIDL). We consider the problem of developing PIDL formulations that can also perform UQ. To this end, we propose a novel physics-informed GAN architecture, termed PID-GAN, where the knowledge of physics is used to inform the learning of both the generator and discriminator models, making ample use of unlabeled data instances. We show that our proposed PID-GAN framework does not suffer from imbalance of generator gradients from multiple loss terms as compared to state-of-the-art. We also empirically demonstrate the efficacy of our proposed framework on a variety of case studies involving benchmark physics-based PDEs as well as imperfect physics.},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD)},
  preview = {pidgan.jpg},
  code={https://github.com/arkadaw9/PID-GAN},
  arxiv={2106.02993},
  pages={237--247},
  selected={true},
  year={2021}
}

@inproceedings{maruf2021maximizing,
  abbr={SDM 20},
  title={Maximizing cohesion and separation in graph representation learning: A distance-aware negative sampling approach},
  author={Maruf, M. and Karpatne, Anuj},
  abstract={The objective of unsupervised graph representation learning (GRL) is to learn a low-dimensional space of node embeddings that reflect the structure of a given unlabeled graph. Existing algorithms for this task rely on negative sampling objectives that maximize the similarity in node embeddings at nearby nodes (referred to as "cohesion") by maintaining positive and negative corpus of node pairs. While positive samples are drawn from node pairs that co-occur in short random walks, conventional approaches construct negative corpus by uniformly sampling random pairs, thus ignoring valuable information about structural dissimilarity among distant node pairs (referred to as "separation"). In this paper, we present a novel Distance-aware Negative Sampling (DNS) which maximizes the separation of distant node-pairs while maximizing cohesion at nearby node-pairs by setting the negative sampling probability proportional to the pair-wise shortest distances. Our approach can be used in conjunction with any GRL algorithm and we demonstrate the efficacy of our approach over baseline negative sampling methods over downstream node classification tasks on a number of benchmark datasets and GRL algorithms.},
  booktitle={Proceedings of the 2021 SIAM International Conference on Data Mining},
  code={https://github.com/sammarfy/DNS},
  pages={271--279},
  year={2020},
  selected={true},
  arxiv={2007.01423},
  preview = {dns.jpg},
  organization={SIAM}
}


@article{al2019irspot,
  abbr={Genomics 19},
  title={{iRSpot-SF}: Prediction of recombination hotspots by incorporating sequence-based features into Pseudo components},
  author={Maruf, M. and Shatabda, Swakkhar},
  website={https://doi.org/10.1016/j.ygeno.2018.06.003},
  journal={Genomics},
  volume={111},
  number={4},
  pages={966--972},
  year={2019},
  publisher={Elsevier}
}

@article{bakics2022extracting,
  abbr={Biodiversity},
  title={Extracting Landmark and Trait Information from Segmented Digital Specimen Images Generated by Artificial Neural Networks},
  author={Bak{\i}{\c{s}}, Yasin and Alt{\i}nta{\c{s}}, Bahad{\i}r and Wang, Xiaojun and Maruf, M. and Karpatne, Anuj and Bart, Henry},
  journal={Biodiversity Information Science and Standards},
  volume={6},
  pages={e94955},
  year={2022},
  publisher={Pensoft Publishers}
}

@article{meghan2023fair,
  abbr={Ecology},
  title={A {FAIR} and modular image-based workflow for knowledge discovery in the emerging field of imageomics},
  author={Balk, Meghan and Bradley, John and Maruf, M. and Altintaş, Bahadir and Bakis, Yasin and Bart Jr., Henry and Breen, David and Florian, Christopher and Greenberg, Jane and Karpatne, Anuj and Karnani, Kevin and Mabee, Paula and Pepper, Joel and Jebbia, Dom and Tabarin, Thibault and Wang, Xiaojun and Lapp, Hilmar},
  journal={Methods in Ecology and Evolution},
  website={https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14327},
  year={2023}
}


@inproceedings{maruf2021biology,
  abbr={Biology},
  title={Biology-guided Neural Network for Fish Trait Discovery},
  author={Maruf, M. and Elhamod, M. and Mandke, PK and Karpatne, A.},
  booktitle={Integrative And Comparative Biology Workshop},
  year={2021}
}

@inproceedings{elhamod2021biology,
  abbr={Biology},
  title={Biology-guided Neural Network for Species Classification},
  author={Elhamod, M. and Maruf, M. and Mandke, PK and Karpatne, A.},
  booktitle={Integrative And Comparative Biology Workshop},
  year={2021}
}

@inproceedings{zeroshot2023imageomics,
    abbr={AAAI 23},
    title={Are Pre-trained Vision Language Models (VLMs) Decent Zero-shot Predictors in Scientific Contexts?},
    author={Maruf, M. and Daw, Arka and Karpatne, Anuj},
    booktitle={first workshop on Imageomics at AAAI},
    year={2023}
}
 

@inproceedings{darka2021aaaiw,
  abbr={AAAI 21},
  title={PID‑GAN: A GAN Framework based on a Physics‑informed Discriminator for Uncertainty Quantification with Physics},
  author={Daw*, Arka and Maruf*, M. and Karpatne, Anuj},
  booktitle={2nd symposium on Science‑Guided AI (SGAI) at (AAAI)},
  year={2021},
}

@inproceedings{daw2020physics,
  abbr={ML4PS NeurIPS},
  title={Physics-Informed Discriminator (PID) for Conditional Generative Adversarial Nets},
  author={Daw, Arka and Maruf, M. and Karpatne, Anuj},
  booktitle={Machine Learning and Physical Sciences Workshop at Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{maruf2020piml,
  abbr={PIML 20},
  title={Informing Neural Networks for Drug Effect Prediction Using Biological Knowledge of Protein-Protein Interactions},
  author={Maruf, M. and Karpatne, Anuj},
  booktitle={3rd Physics Informed Machine Learning (PIML) Workshop},
  year={2020}
}

@inproceedings{mridul2023imageomics,
    abbr={AAAI 23},
    title={Conditioning Diffusion Models Using the Knowledge of Phylogeny for Understanding Species Evolution},
    author={Khurana, Mridul and Daw, Arka and Maruf, M. and Karpatne, Anuj},
    booktitle={first workshop on Imageomics at AAAI},
    year={2023}}
}


@inproceedings{kazi2023imageomics,
    abbr={AAAI 23},
    title={Phylo-GNN: Phylogeny-guided Graph Neural Network Approach for Fine-Grained Image Trait Identification},
    author={Mehrab, Kazi and Daw, Arka and Maruf, M. and Karpatne, Anuj},
    booktitle={first workshop on Imageomics at AAAI},
    year={2023}}
}

